README file for Programming Assignment 2 (C++ edition)
=====================================================

Your directory should contain the following files:

 Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [cool root]/src/PA2/lextest.cc
 mycoolc         -> [cool root]/PA2/mycoolc
 stringtab.cc    -> [cool root]/PA2/stringtab.cc
 utilities.cc    -> [cool root]/PA2/utilities.cc
 handle_flags.cc -> [cool root]/PA2/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[cool root]/PA2

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2
----------------

The implementation is pretty simple. We make use of Flex's start conditions to
conditionally apply certain rules depending on whether we are inside a string
literal, a (nested) comment, or in regular code.

For regular code, we use the principle of precedence to match keywords before
identifiers, so keywords are never confused as identifiers, which simplifies the
rules for identifiers. We do not condition on word boundaries, so for example
123abc123 will be interpreted as the int literal 123 followed by the object id
"abc123". We exploit maximal matching so that for example case1234 is
interpreted as a single object identifier rather than the CASE keyword followed
by an integer. Whitespace is ignored.  Non-whitespace characters which cannot
appear in keywords, operators, or identifiers will be caught by a "default"
rule, which matches the first character of input when no rules have matched.

For nested comments, we use an exclusive start condition to cleanly separate
rules which should only apply within comments. We enter this start condition (if
it is not already active) when encountering a "(*". Since comments can can be
arbitrarily deeply nested, we keep track of the current "depth" of the comment
using a static global. When the depth is 1 and we encounter a "*)", we exit the
start condition, causing the lexer to interpret what follows as normal code.
Everything other than a "(*" or a "*)" when in comment mode is ignored.

For strings, we also use an exclusive start condition to cleanly define rules
which should only apply within string literals. We enter this start condition
when encountering an open double quotation mark. In strings, we scan either one
or two characters at a time, two when encountering an escape character ("\") so
as to include the escaped character as well. Again maximal matching keeps the
rule for non-escaped characters simple.  Once any necessary escaping has been
applied, the character is appended on to a buffer.  If during this process the
buffer becomes full or we encounter a null character, we return an ERROR token
so the line number reflects where the error occurred rather than the end of the
string, and we set an internal flag to indicate that the string is not valid. If
we encounter an unescaped new line, the string is considered to be terminated
and invalid and we immeditely exit the start condition. If there have been no
unescaped new lines, when we encounter another unescaped quote, assuming no
errors have occurred in scanning the string, we terminate the buffer with a null
character and copy the contents of the buffer to the string table and also exit
the start condition so we can scan code normally again.
